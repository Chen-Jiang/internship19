11.19
I planned to process our data using deduce tool, use one of the dataset(fibre), however found the CSV file is not a standard CSV file, so preprocess the data first and make sure the file is standard csv file, also adjust the format of the data, correct some errors, such as some contents are written in a same cell.
Also read the adjusted csv file and create a dictionary of records

11.20
Work I have done:
1. I planned to experiment the algorithm in csv-example folder provided by dedupe, get familiar with the example algorithm;
2. I have preprocessed the raw data yesterday, and today based on yester's worl, I transfered the OrderedDict to teh regular dictionary format so that the data can be dealed with by the algorithm;
3. According to the algorithm, after preprocessing the raw data, try to use active learning to train the dataset;
Problems I met:
1. do not have good understanding of the algorithm provided by the example, expecially about the add cluster part (in this part, several columns are added to the input file), so still need to work more on the experiment.

11.21
Work I have done:
1. see dedupe's document and have better understanding of algorithm;
2. run yesterday's code on sample data and original data;
3. when running code on original there are some bugs, and worked on fixing bugs, such as ZeroDivisionError: float division; Still fixing...not finished
Problems I met:
1. How to evaluate the performance of the result? In the provided examples, there is a file with manual labels so that the results can be evaluated. How can we evaluate our results?

11.22
Work I have done:
1. fix the bug and apply the algorithm to the original dataset, get some results
2. fix some code, such as add the low() to make sure identify the same contents more precisely
Problems I met:
1. How to evaluate the result of the algorithm?

11.25
Work I have done:
1. use google to learn about TDD, what is TDD, and how to implement TDD
2. find several examples from google to practice using TDD when programming, language is Python

11.26
Work I have done:
1. do some TDD exercises, please see the PyTDDProject folder.
2. finish the TDD notes, please go to PyTDDProject/
3. google about how to evaluate the result of machine learning algorithm

11.27
Work I have done:
1. Attend the Intro to TDD meeting
2. Google and write down how to evaluate performance of unsupervised learning, below is my thoughts(I will also upload the file to git):
Methods:

1. Transfer unsupervised learning to supervised learning.
Choose some instances randomly from the original dataset (such as choose 10 percent of total number of original data, and including repeated and unrepeated instances). Then give them labels manually, and then divide them into training data and test data. Apply the algorithm to training data and test data and to see the performance, when the performance is good (use standard such as Precision……), then apply the algorithm to the all data.

2. Run unsupervised learning first, then verify the results
Choose some instances randomly, and give them labels manually and save to another file. Run the unlabeled original data, then compare the algorithm’s result to data which has been labeled.

3. Assumption: among our data, the duplicate data accounts for a small portion
Run the unlabeled, original data first, then we will get the results about what are duplicate data. Then we pay attention to those who have been predicted duplicate. We compare the similarity of fields of different data(such as regular expression, I assume that a lot of information will be same or similar), to improve the performance, we can set different weights to different fields according to their importance.

4. Try Ensemble learning
Use some unsupervised learning as base learner so that combine the results from different methods.
